{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5c1910a-3ba4-4607-95c1-317d50785d84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|            - |       124|           50|\n|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|            - |       124|           50|\n|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|  4400|            - |       101|           10|\n|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 13000|            - |       100|           20|\n|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|  6000|            - |       201|           20|\n|        203|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|  6500|            - |       101|           40|\n|        204|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|            - |       101|           70|\n|        205|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 12008|            - |       101|          110|\n|        206|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT|  8300|            - |       205|          110|\n|        100|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 24000|            - |        - |           90|\n+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"EmployeeData\").getOrCreate()\n",
    "df = spark.read.csv(\"/FileStore/tables/employees-1.csv\", header=True, inferSchema=True)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89153d94-b018-4bec-8700-f2776444f861",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- EMPLOYEE_ID: integer (nullable = true)\n |-- FIRST_NAME: string (nullable = true)\n |-- LAST_NAME: string (nullable = true)\n |-- EMAIL: string (nullable = true)\n |-- PHONE_NUMBER: string (nullable = true)\n |-- HIRE_DATE: string (nullable = true)\n |-- JOB_ID: string (nullable = true)\n |-- SALARY: integer (nullable = true)\n |-- COMMISSION_PCT: string (nullable = true)\n |-- MANAGER_ID: string (nullable = true)\n |-- DEPARTMENT_ID: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d9d104d-4197-4d4f-ba12-64ef4f0e18a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK| 32600|            - |       124|           50|\n|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK| 32600|            - |       124|           50|\n|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST| 34400|            - |       101|           10|\n|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 43000|            - |       100|           20|\n|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP| 36000|            - |       201|           20|\n|        203|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP| 36500|            - |       101|           40|\n|        204|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 40000|            - |       101|           70|\n|        205|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 42008|            - |       101|          110|\n|        206|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT| 38300|            - |       205|          110|\n|        100|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 54000|            - |        - |           90|\n|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP| 47000|            - |       100|           90|\n|        102|       Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP| 47000|            - |       100|           90|\n|        103| Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG| 39000|            - |       102|           60|\n|        104|     Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG| 36000|            - |       103|           60|\n|        105|     David|   Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG| 34800|            - |       103|           60|\n|        106|     Valli|Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG| 34800|            - |       103|           60|\n|        107|     Diana|  Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG| 34200|            - |       103|           60|\n|        108|     Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR| 42008|            - |       101|          100|\n|        109|    Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT| 39000|            - |       108|          100|\n|        110|      John|     Chen|   JCHEN|515.124.4269|28-SEP-05|FI_ACCOUNT| 38200|            - |       108|          100|\n+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_updated = df.withColumn(\"SALARY\", col(\"SALARY\") + 30000)\n",
    "df_updated.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21a3ce04-ec65-4422-9cf2-61a7e783506a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Coding: Filter out rows where salary < 50,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "087d6b96-7dcd-48d7-b864-bccb1336bd5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+-----+------------+---------+-------+------+--------------+----------+-------------+\n|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|EMAIL|PHONE_NUMBER|HIRE_DATE| JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n+-----------+----------+---------+-----+------------+---------+-------+------+--------------+----------+-------------+\n|        100|    Steven|     King|SKING|515.123.4567|17-JUN-03|AD_PRES| 54000|            - |        - |           90|\n+-----------+----------+---------+-----+------------+---------+-------+------+--------------+----------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df_updated.filter(df_updated.SALARY >= 50000)\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f542d4c8-b120-4a76-ab4c-4aab9667c80e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Coding: Read CSV, drop nulls, save as Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de89b94-5060-4324-bee4-b97a3f713234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|            - |       124|           50|\n|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|            - |       124|           50|\n|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|  4400|            - |       101|           10|\n|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 13000|            - |       100|           20|\n|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|  6000|            - |       201|           20|\n|        203|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|  6500|            - |       101|           40|\n|        204|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|            - |       101|           70|\n|        205|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 12008|            - |       101|          110|\n|        206|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT|  8300|            - |       205|          110|\n|        100|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 24000|            - |        - |           90|\n+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"EmployeeData1\").getOrCreate()\n",
    "df1 = spark.read.csv(\"/FileStore/tables/employees-1.csv\", header=True, inferSchema=True)\n",
    "df1.show(10)\n",
    "\n",
    "df_cleaned = df1.replace(\"-\", None)\n",
    "df_cleaned = df_cleaned.dropna()\n",
    "\n",
    "df_cleaned.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"default.cleaned_employees1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edc7a49c-80dc-4a74-a736-b638659afabe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Coding: Group by department and calculate avg salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3c83bb3-5de4-40bb-b49c-bc26ab1a031d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n|DEPARTMENT_ID|        AVG_SALARY|\n+-------------+------------------+\n|           20|            9500.0|\n|           40|            6500.0|\n|          100| 8601.333333333334|\n|           10|            4400.0|\n|           50|3721.7391304347825|\n|           70|           10000.0|\n|           90|19333.333333333332|\n|           60|            5760.0|\n|          110|           10154.0|\n|           30|            4150.0|\n+-------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "df_grouped = df1.groupBy(\"DEPARTMENT_ID\").agg(avg(\"SALARY\").alias(\"AVG_SALARY\"))\n",
    "df_grouped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0158bce7-d7e8-498c-9044-690af331ef0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Coding: Remove duplicate rows based on email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6efb0f64-423a-40e2-baf1-66ae6bc9fb24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+--------+------------+---------+----------+------+--------------+----------+-------------+\n|EMPLOYEE_ID| FIRST_NAME|  LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n+-----------+-----------+-----------+--------+------------+---------+----------+------+--------------+----------+-------------+\n|        121|       Adam|      Fripp|  AFRIPP|650.123.2234|10-APR-05|    ST_MAN|  8200|            - |       100|           50|\n|        103|  Alexander|     Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG|  9000|            - |       102|           60|\n|        115|  Alexander|       Khoo|   AKHOO|515.127.4562|18-MAY-03|  PU_CLERK|  3100|            - |       114|           30|\n|        104|      Bruce|      Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG|  6000|            - |       103|           60|\n|        105|      David|     Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG|  4800|            - |       103|           60|\n|        109|     Daniel|     Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT|  9000|            - |       108|          100|\n|        199|    Douglas|      Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|            - |       124|           50|\n|        107|      Diana|    Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG|  4200|            - |       103|           60|\n|        198|     Donald|   OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|            - |       124|           50|\n|        114|        Den|   Raphaely|DRAPHEAL|515.127.4561|07-DEC-02|    PU_MAN| 11000|            - |       100|           30|\n|        118|        Guy|     Himuro| GHIMURO|515.127.4565|15-NOV-06|  PU_CLERK|  2600|            - |       114|           30|\n|        204|    Hermann|       Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|            - |       101|           70|\n|        136|      Hazel| Philtanker|HPHILTAN|650.127.1634|06-FEB-08|  ST_CLERK|  2200|            - |       122|           50|\n|        126|      Irene|Mikkilineni|IMIKKILI|650.124.1224|28-SEP-06|  ST_CLERK|  2700|            - |       120|           50|\n|        111|     Ismael|    Sciarra|ISCIARRA|515.124.4369|30-SEP-05|FI_ACCOUNT|  7700|            - |       108|          100|\n|        131|      James|     Marlow| JAMRLOW|650.124.7234|16-FEB-05|  ST_CLERK|  2500|            - |       121|           50|\n|        110|       John|       Chen|   JCHEN|515.124.4269|28-SEP-05|FI_ACCOUNT|  8200|            - |       108|          100|\n|        127|      James|     Landry| JLANDRY|650.124.1334|14-JAN-07|  ST_CLERK|  2400|            - |       120|           50|\n|        133|      Jason|     Mallin| JMALLIN|650.127.1934|14-JUN-04|  ST_CLERK|  3300|            - |       122|           50|\n|        112|Jose Manuel|      Urman| JMURMAN|515.124.4469|07-MAR-06|FI_ACCOUNT|  7800|            - |       108|          100|\n+-----------+-----------+-----------+--------+------------+---------+----------+------+--------------+----------+-------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_deduplicated = df1.dropDuplicates([\"EMAIL\"])\n",
    "df_deduplicated.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6456c9b7-37cd-43ce-8626-4c2a0d98df6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Short Answer: Explain lazy evaluation in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2a3bf3a-adfd-47d8-a1dc-639aed38ca00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Spark delays execution of transformations until an action is triggered.\n",
    "It builds a logical execution plan (DAG) instead of running each step immediately.\n",
    "This optimization helps reduce redundant computations and improves performance.\n",
    "Transformations (e.g., filter(), map()) are lazy, meaning they donâ€™t execute immediately.\n",
    "Actions (e.g., show(), collect(), count()) trigger execution of all preceding transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff31ed56-6876-4781-ad18-7ee13ec723be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n|EMPLOYEE_ID|SALARY|\n+-----------+------+\n|        201| 13000|\n|        205| 12008|\n|        100| 24000|\n|        101| 17000|\n|        102| 17000|\n|        108| 12008|\n|        114| 11000|\n+-----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df.filter(df[\"SALARY\"] > 10000)  # Transformation (Lazy, no execution yet)\n",
    "df_filtered = df_filtered.select(\"EMPLOYEE_ID\", \"SALARY\")  # Another transformation (Still no execution)\n",
    "df_filtered.show()  # Action (Now Spark runs all transformations)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2467341257496622,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "IO_Test_DE_Mayuresh_Pawashe",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}